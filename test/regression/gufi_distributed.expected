#####################################
# slurm jobs

# Index Source Tree
$ gufi_dir2index_distributed --sbatch "sbatch" --gufi_dir2index "gufi_dir2index" "find.sh" slurm "hostfile" 1 "prefix" "search2" 2>/dev/null
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for slurm jobs to complete

# Query Index
$ gufi_query_distributed --sbatch "sbatch" --gufi_query "gufi_query" --threads 2 --delim "|" "find.sh" slurm "hostfile" 1 "search2/prefix" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;"
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for slurm jobs to complete
cat the following slurm job output files to get complete results:
    0
    1
    2
    3
    4

# combine output files
$ cat slurm.fake-0.out slurm.fake-1.out slurm.fake-2.out slurm.fake-3.out slurm.fake-4.out
prefix2/.hidden|10
prefix2/1KB|1024
prefix2/1MB|1048576
prefix2/directory/executable|1
prefix2/directory/readonly|2
prefix2/directory/subdirectory/directory_symlink|4
prefix2/directory/subdirectory/repeat_name|5
prefix2/directory/subdirectory|6
prefix2/directory/writable|3
prefix2/directory|7
prefix2/empty_directory|8
prefix2/file_symlink|9
prefix2/leaf_directory/leaf_file1|11
prefix2/leaf_directory/leaf_file2|12
prefix2/leaf_directory|13
prefix2/old_file|0
prefix2/repeat_name|14
prefix2/unusual#? directory ,/unusual, name?#|15
prefix2/unusual#? directory ,|16
prefix2|17

# Diff original index results against the combined results
$ diff <("gufi_query" -d "|" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" "prefix" | sort) <(cat slurm.fake-0.out slurm.fake-1.out slurm.fake-2.out slurm.fake-3.out slurm.fake-4.out | sort | sed 's/search2\/prefix/search\/prefix/g')

# Diff original index results against querying the new index from a single node
$ diff <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "prefix" | sort) <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "search2/prefix" | sort | sed 's/search2\/prefix/search\/prefix/g')

# Convert source tree to trace files
$ gufi_dir2trace_distributed --sbatch "sbatch" --gufi_dir2trace "gufi_dir2trace" -d "|" "find.sh" slurm "hostfile" 1 "prefix" "traces"
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for slurm jobs to complete
Index can now be created from "traces.*"

# Print contents of traces files
$ cat traces.0.0 traces.1.0 traces.2.0 traces.3.0 traces.0 | awk -F'|' '{ print $1 }'
prefix
prefix/.hidden
prefix/1KB
prefix/1MB
prefix/directory
prefix/directory/executable
prefix/directory/readonly
prefix/directory/subdirectory
prefix/directory/subdirectory/directory_symlink
prefix/directory/subdirectory/repeat_name
prefix/directory/writable
prefix/empty_directory
prefix/file_symlink
prefix/leaf_directory
prefix/leaf_directory/leaf_file1
prefix/leaf_directory/leaf_file2
prefix/old_file
prefix/repeat_name
prefix/unusual#? directory ,
prefix/unusual#? directory ,/unusual, name?#

# Diff original index results against the trace files
$ diff <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "prefix" | sort | sed 's%search/%%g;') <(cat traces.0.0 traces.1.0 traces.2.0 traces.3.0 traces.0 | awk -F'|' '{ print $1 }' | sort)

# Use existing group files (path_list.4 does not exist)
$ gufi_dir2index_distributed --sbatch "sbatch" --gufi_dir2index "gufi_dir2index" --use-existing-group-files "find.sh" slurm "hostfile" 1 "prefix" "search2" 2>/dev/null
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
    Process upper directories on 127.0.0.1
Waiting for slurm jobs to complete

# Generate treesummary tables
$ gufi_treesummary_all_distributed --sbatch "sbatch" --gufi_treesummary_all "gufi_treesummary_all" --use-existing-group-files "find.sh" slurm "hostfile" 1 "search2/prefix" 2>/dev/null
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
Waiting for slurm jobs to complete
    Process upper directories on 127.0.0.1

# Query the treesummary tables
$ gufi_query -n 2 -d "|" -T "SELECT path(), totsubdirs, totfiles FROM treesummary;" "search2/prefix"
search2/prefix/directory/subdirectory|0|1
search2/prefix/directory|1|4
search2/prefix/empty_directory|0|0
search2/prefix/leaf_directory|0|2
search2/prefix/unusual#? directory ,|0|1
search2/prefix|5|12

# Roll up the index
$ gufi_rollup_distributed --sbatch "sbatch" --gufi_rollup "gufi_rollup" --use-existing-group-files "find.sh" slurm "hostfile" 1 "search2/prefix" 2>/dev/null
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
Waiting for slurm jobs to complete
    Process upper directories on 127.0.0.1

# Query the rolled up index
$ gufi_query -n 2 -d "|" -T "SELECT name, isroot, rollupscore FROM summary;" "search2/prefix"
prefix/directory/subdirectory|0|1
prefix/directory|0|1
prefix/empty_directory|0|1
prefix/leaf_directory|0|1
prefix/unusual#? directory ,|0|1
prefix|1|1

# Unroll up the index
$ gufi_unrollup_distributed --sbatch "sbatch" --gufi_unrollup "gufi_unrollup" --use-existing-group-files "find.sh" slurm "hostfile" 1 "search2/prefix" 2>/dev/null
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
Waiting for slurm jobs to complete
    Process upper directories on 127.0.0.1

# Query the unrolled up index
$ gufi_query -n 2 -d "|" -T "SELECT name, isroot, rollupscore FROM summary;" "search2/prefix"
directory|1|0
empty_directory|1|0
leaf_directory|1|0
prefix|1|0
subdirectory|1|0
unusual#? directory ,|1|0

#####################################

#####################################
# ssh jobs

# Index Source Tree
$ gufi_dir2index_distributed --ssh "ssh" --gufi_dir2index "gufi_dir2index" "find.sh" ssh "hostfile" 1 "prefix" "search2" 2>/dev/null
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for ssh jobs to complete

# Query Index
$ gufi_query_distributed --ssh "ssh" --gufi_query "gufi_query" --threads 2 --delim "|" "find.sh" ssh "hostfile" 1 "search2/prefix" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" --output_prefix "output"
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for ssh jobs to complete
cat "output.*" to get complete results

# combine output files
$ cat output.localhost.0.0 output.127.0.0.1.1.0 output.localhost.2.0 output.127.0.0.1.3.0 output.127.0.0.1.top.0 output.localhost.0.1 output.127.0.0.1.1.1 output.localhost.2.1 output.127.0.0.1.3.1 output.127.0.0.1.top.1
prefix2/.hidden|10
prefix2/1KB|1024
prefix2/1MB|1048576
prefix2/directory/executable|1
prefix2/directory/readonly|2
prefix2/directory/subdirectory/directory_symlink|4
prefix2/directory/subdirectory/repeat_name|5
prefix2/directory/subdirectory|6
prefix2/directory/writable|3
prefix2/directory|7
prefix2/empty_directory|8
prefix2/file_symlink|9
prefix2/leaf_directory/leaf_file1|11
prefix2/leaf_directory/leaf_file2|12
prefix2/leaf_directory|13
prefix2/old_file|0
prefix2/repeat_name|14
prefix2/unusual#? directory ,/unusual, name?#|15
prefix2/unusual#? directory ,|16
prefix2|17

# Diff original index results against the combined results
$ diff <("gufi_query" -d "|" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" "prefix" | sort) <(cat output.localhost.0.0 output.127.0.0.1.1.0 output.localhost.2.0 output.127.0.0.1.3.0 output.127.0.0.1.top.0 output.localhost.0.1 output.127.0.0.1.1.1 output.localhost.2.1 output.127.0.0.1.3.1 output.127.0.0.1.top.1 | sort | sed 's/search2\/prefix/search\/prefix/g')

# Diff original index results against querying the new index from a single node
$ diff <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "prefix" | sort) <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "search2/prefix" | sort | sed 's/search2\/prefix/search\/prefix/g')

# Convert source tree to trace files
$ gufi_dir2trace_distributed --ssh "ssh" --gufi_dir2trace "gufi_dir2trace" -d "|" "find.sh" ssh "hostfile" 1 "prefix" "traces"
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for ssh jobs to complete
Index can now be created from "traces.*"

# Print contents of traces files
$ cat traces.0.0 traces.1.0 traces.2.0 traces.3.0 traces.0 | awk -F'|' '{ print $1 }'
prefix
prefix/.hidden
prefix/1KB
prefix/1MB
prefix/directory
prefix/directory/executable
prefix/directory/readonly
prefix/directory/subdirectory
prefix/directory/subdirectory/directory_symlink
prefix/directory/subdirectory/repeat_name
prefix/directory/writable
prefix/empty_directory
prefix/file_symlink
prefix/leaf_directory
prefix/leaf_directory/leaf_file1
prefix/leaf_directory/leaf_file2
prefix/old_file
prefix/repeat_name
prefix/unusual#? directory ,
prefix/unusual#? directory ,/unusual, name?#

# Diff original index results against the trace files
$ diff <(gufi_query -d "|" -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "prefix" | sort | sed 's%search/%%g;') <(cat traces.0.0 traces.1.0 traces.2.0 traces.3.0 traces.0 | awk -F'|' '{ print $1 }' | sort)

# Use existing group files (path_list.4 does not exist)
$ gufi_dir2index_distributed --ssh "ssh" --gufi_dir2index "gufi_dir2index" --use-existing-group-files "find.sh" ssh "hostfile" 1 "prefix" "search2" 2>/dev/null | tail -n 9
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
    Process upper directories on 127.0.0.1
Waiting for ssh jobs to complete

# Generate treesummary tables
$ gufi_treesummary_all_distributed --ssh "ssh" --gufi_treesummary_all "gufi_treesummary_all" --use-existing-group-files "find.sh" ssh "hostfile" 1 "search2/prefix" 2>/dev/null
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
Waiting for ssh jobs to complete
    Process upper directories on 127.0.0.1

# Query the treesummary tables
$ gufi_query -n 2 -d "|" -T "SELECT path(), totsubdirs, totfiles FROM treesummary;" "search2/prefix"
search2/prefix/directory/subdirectory|0|1
search2/prefix/directory|1|4
search2/prefix/empty_directory|0|0
search2/prefix/leaf_directory|0|2
search2/prefix/unusual#? directory ,|0|1
search2/prefix|5|12

# Roll up the index
$ gufi_rollup_distributed --ssh "ssh" --gufi_rollup "gufi_rollup" --use-existing-group-files "find.sh" ssh "hostfile" 1 "search2/prefix" 2>/dev/null | tail -n 9
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
Waiting for ssh jobs to complete
    Process upper directories on 127.0.0.1

# Query the rolled up index
$ gufi_query -n 2 -d "|" -T "SELECT name, isroot, rollupscore FROM summary;" "search2/prefix"
prefix/directory/subdirectory|0|1
prefix/directory|0|1
prefix/empty_directory|0|1
prefix/leaf_directory|0|1
prefix/unusual#? directory ,|0|1
prefix|1|1

# Unroll up the index
$ gufi_unrollup_distributed --ssh "ssh" --gufi_unrollup "gufi_unrollup" --use-existing-group-files "find.sh" ssh "hostfile" 1 "search2/prefix" 2>/dev/null
Using existing files
    Range 0: Contents of path_list.0 on localhost
    Range 1: Contents of path_list.1 on 127.0.0.1
    Range 2: Contents of path_list.2 on localhost
    Range 3: Contents of path_list.3 on 127.0.0.1
    Range 4: Contents of path_list.4 on localhost
Waiting for ssh jobs to complete
    Process upper directories on 127.0.0.1

# Query the unrolled up index
$ gufi_query -n 2 -d "|" -T "SELECT name, isroot, rollupscore FROM summary;" "search2/prefix"
directory|1|0
empty_directory|1|0
leaf_directory|1|0
prefix|1|0
subdirectory|1|0
unusual#? directory ,|1|0

#####################################

#####################################
# Index with an existing path list
# Generate path list
$ find.sh "prefix" 1 > "path_list"

# Index Source Tree
$ gufi_dir2index_distributed --ssh "ssh" --gufi_dir2index "gufi_dir2index" --use-existing-paths "path_list" "find.sh" ssh "hostfile" 1 "prefix" "search2" 2>/dev/null
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for ssh jobs to complete

# Query Index
$ gufi_query_distributed --ssh "ssh" --gufi_query "gufi_query" --threads 2 --delim "|" "find.sh" ssh "hostfile" 1 "search2/prefix" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" --output_prefix "output"
Splitting 4 paths into 5 groups of max size 1
    Range 0: 1 path on localhost
        directory directory
    Range 1: 1 path on 127.0.0.1
        empty_directory empty_directory
    Range 2: 1 path on localhost
        leaf_directory leaf_directory
    Range 3: 1 path on 127.0.0.1
        unusual#? directory , unusual#? directory ,
    Process upper directories on 127.0.0.1
Waiting for ssh jobs to complete
cat "output.*" to get complete results

# combine output files
$ cat output.localhost.0.0 output.127.0.0.1.1.0 output.localhost.2.0 output.127.0.0.1.3.0 output.127.0.0.1.top.0 output.localhost.0.1 output.127.0.0.1.1.1 output.localhost.2.1 output.127.0.0.1.3.1 output.127.0.0.1.top.1
prefix2/.hidden|10
prefix2/1KB|1024
prefix2/1MB|1048576
prefix2/directory/executable|1
prefix2/directory/readonly|2
prefix2/directory/subdirectory/directory_symlink|4
prefix2/directory/subdirectory/repeat_name|5
prefix2/directory/subdirectory|6
prefix2/directory/writable|3
prefix2/directory|7
prefix2/empty_directory|8
prefix2/file_symlink|9
prefix2/leaf_directory/leaf_file1|11
prefix2/leaf_directory/leaf_file2|12
prefix2/leaf_directory|13
prefix2/old_file|0
prefix2/repeat_name|14
prefix2/unusual#? directory ,/unusual, name?#|15
prefix2/unusual#? directory ,|16
prefix2|17

# Diff original index results against the combined results
$ diff <("gufi_query" -d "|" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" "prefix" | sort) <(cat output.localhost.0.0 output.127.0.0.1.1.0 output.localhost.2.0 output.127.0.0.1.3.0 output.127.0.0.1.top.0 output.localhost.0.1 output.127.0.0.1.1.1 output.localhost.2.1 output.127.0.0.1.3.1 output.127.0.0.1.top.1 | sort | sed 's/search2\/prefix/search\/prefix/g')

# Diff original index results against querying the new index from a single node
$ diff <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "prefix" | sort) <(gufi_query -S "SELECT rpath(sname, sroll) FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name FROM vrpentries;" "search2/prefix" | sort | sed 's/search2\/prefix/search\/prefix/g')

#####################################

#####################################
# Errors
# Bad source path
$ gufi_dir2index_distributed --ssh "ssh" --gufi_dir2index "gufi_dir2index" --use-existing-group-files "find.sh" ssh "hostfile" 1 "hostfile" "search2" 2>&1 | tail -n 1
gufi_dir2index_distributed: error: argument input_dir: Bad directory: hostfile

# Missing argument to gufi_query_distributed
$ gufi_query_distributed --ssh "ssh" --gufi_query "gufi_query" --threads 2 --delim "|" "find.sh" ssh "hostfile" 1 "search2/prefix" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" 2>&1 | tail -n 1
RuntimeError: --output_prefix must be set

# Bad executable
$ gufi_query_distributed --ssh "ssh" --gufi_query "hostfile" --threads 2 --delim "|" "find.sh" ssh "hostfile" 1 "search2/prefix" -S "SELECT rpath(sname, sroll), mtime FROM vrsummary;" -E "SELECT rpath(sname, sroll) || '/' || name, mtime FROM vrpentries;" 2>&1 | tail -n 1
gufi_query_distributed: error: argument --gufi_query: Bad executable: hostfile

# Bad hostfile
$ gufi_query_distributed "find.sh" ssh "hostfile" 1 "search2/prefix" 2>&1 | tail -n 1
RuntimeError: Need at least 2 nodes in node list

# Cannot use existing path list and group files at the same time 
$ gufi_dir2index_distributed --use-existing-paths "path_list" --use-existing-group-files "find.sh" ssh "hostfile" 1 "prefix" "search2" 2>&1 | tail -n 1
gufi_dir2index_distributed: error: argument --use-existing-group-files: not allowed with argument --use-existing-paths

#####################################
