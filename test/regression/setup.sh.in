#!/usr/bin/env bash
# This file is part of GUFI, which is part of MarFS, which is released
# under the BSD license.
#
#
# Copyright (c) 2017, Los Alamos National Security (LANS), LLC
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without modification,
# are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this
# list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
# this list of conditions and the following disclaimer in the documentation and/or
# other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors
# may be used to endorse or promote products derived from this software without
# specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
# INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
# OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
#
# From Los Alamos National Security, LLC:
# LA-CC-15-039
#
# Copyright (c) 2017, Los Alamos National Security, LLC All rights reserved.
# Copyright 2017. Los Alamos National Security, LLC. This software was produced
# under U.S. Government contract DE-AC52-06NA25396 for Los Alamos National
# Laboratory (LANL), which is operated by Los Alamos National Security, LLC for
# the U.S. Department of Energy. The U.S. Government has rights to use,
# reproduce, and distribute this software.  NEITHER THE GOVERNMENT NOR LOS
# ALAMOS NATIONAL SECURITY, LLC MAKES ANY WARRANTY, EXPRESS OR IMPLIED, OR
# ASSUMES ANY LIABILITY FOR THE USE OF THIS SOFTWARE.  If software is
# modified to produce derivative works, such modified software should be
# clearly marked, so as not to confuse it with the version available from
# LANL.
#
# THIS SOFTWARE IS PROVIDED BY LOS ALAMOS NATIONAL SECURITY, LLC AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
# THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL LOS ALAMOS NATIONAL SECURITY, LLC OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
# OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
# IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
# OF SUCH DAMAGE.



# source this file in regression test scripts

set -e

if [[ "$#" -ne "2" ]]
then
    echo "Syntax: $0 <test name> <generate index>" 1>&2
    exit 1
fi

TEST_NAME="$1"
GENERATE_INDEX="$2"

TEST_WORKING_DIRECTORY="@TEST_WORKING_DIRECTORY@"

if [[ -z "${TEST_WORKING_DIRECTORY}" ]]
then
    TEST_WORKING_DIRECTORY="$(pwd)"
fi

# create a subdirectory to place individual tests into
TEST_DIR="${TEST_WORKING_DIRECTORY}/${TEST_NAME}-$(date +%s)"
TEST_DIR_LATEST="${TEST_WORKING_DIRECTORY}/${TEST_NAME}"

# common test output file name
# shellcheck disable=SC2034
TEST_OUTPUT="out"

SRCDIR="${TEST_DIR}/prefix"
BASENAME="$(basename ${SRCDIR})"
THREADS=2

TRACE="trace"
TRACES=()
for (( i = 0; i < THREADS; i++ ));
do
    TRACES+=("${TRACE}.${i}")
done
DELIM="|"
# shellcheck disable=SC2034
BADTRACE="badtrace"
# shellcheck disable=SC2034
BADDELIM="?"

SEARCH="search"
INDEXROOT="${SEARCH}/${BASENAME}"

# skip file (list of directory basenames)
SKIP="skip"

# shellcheck disable=SC2034
USER_ID="$(id -u)"
# shellcheck disable=SC2034
USER_NAME="$(id -un)"
# shellcheck disable=SC2034
GROUP_ID="$(id -g)"
# shellcheck disable=SC2034
GROUP_NAME="$(id -gn)"
# shellcheck disable=SC2034
TEST_USER_ID="1001"
# shellcheck disable=SC2034
TEST_USER_NAME="user"
# shellcheck disable=SC2034
TEST_GROUP_ID="${TEST_USER_ID}"
# shellcheck disable=SC2034
TEST_GROUP_NAME="group"

# call at end of each test that sources this file
# clean up if there are no errors
setup_cleanup() {
    if [[ -d "${TEST_WORKING_DIRECTORY}" ]]
    then
        # remove existing output dir (should never exist) and link to latest output
        rm -rf "${TEST_DIR}" "${TEST_DIR_LATEST}"

        # find latest output directory
        PREVIOUS=$(find "${TEST_WORKING_DIRECTORY}" -mindepth 1 -maxdepth 1 -name "${TEST_NAME}-*" -type d | sort -nr | head -n 1)

        # if one exists, create a link to it
        if [[ -n "${PREVIOUS}" ]]
        then
            ln -sf "${PREVIOUS}" "${TEST_DIR_LATEST}"
        fi
    fi
}

# always clean up existing data
setup_cleanup

mkdir -p "${TEST_DIR}"

# link to new test output
#
# at end of test, will either point to current output
# or be changed to previous test output if it exists
rm -f "${TEST_DIR_LATEST}"               # need this because ln -f is not replacing
ln -s "${TEST_DIR}" "${TEST_DIR_LATEST}"

cd "${TEST_DIR}"

umask 002
export TZ=UTC
export LC_ALL="C"
export PATH="@CMAKE_BINARY_DIR@/scripts:${PATH}"
export PYTHONPATH="@CMAKE_BINARY_DIR@/scripts:@CMAKE_CURRENT_BINARY_DIR@:${PYTHONPATH}"

# generate a fake config file
# shellcheck disable=SC2046
CONFIG="$(@PYTHON_INTERPRETER@ -c 'import gufi_tool, os; print(os.path.realpath(gufi_tool.CONFIG_PATH))')"
(
    echo "Threads=1"
    echo "Query=@CMAKE_BINARY_DIR@/src/gufi_query"
    echo "Stat=@CMAKE_BINARY_DIR@/src/gufi_stat_bin"
    echo "IndexRoot=${SEARCH}"
    echo "OutputBuffer=4096"
) > "${CONFIG}"
chmod 666 "${CONFIG}"

echo "directory" > "${SKIP}"

# paths of all executables
SQLITE3="@DEP_INSTALL_PREFIX@/sqlite3/bin/sqlite3"
GUFI_TOOL="@CMAKE_CURRENT_BINARY_DIR@/gufi_tool.py"
DELUIDGIDSUMMARYRECS="@CMAKE_BINARY_DIR@/examples/deluidgidsummaryrecs"
GENERATEGIDSUMMARY="@CMAKE_BINARY_DIR@/examples/generategidsummary"
GENERATETREE="@CMAKE_CURRENT_BINARY_DIR@/generatetree.sh"
GENERATEUIDSUMMARY="@CMAKE_BINARY_DIR@/examples/generateuidsummary"
GENGIDSUMMARYAVOIDENTRIESSCAN="@CMAKE_BINARY_DIR@/examples/gengidsummaryavoidentriesscan"
GENUIDSUMMARYAVOIDENTRIESSCAN="@CMAKE_BINARY_DIR@/examples/genuidsummaryavoidentriesscan"
GROUPFILESPACEHOG="@CMAKE_BINARY_DIR@/examples/groupfilespacehog"
GROUPFILESPACEHOGUSESUMMARY="@CMAKE_BINARY_DIR@/examples/groupfilespacehogusesummary"
GUFI_DIR2INDEX="@CMAKE_BINARY_DIR@/src/gufi_dir2index"
GUFI_DIR2TRACE="@CMAKE_BINARY_DIR@/src/gufi_dir2trace"
GUFI_FIND="${GUFI_TOOL} find"
GUFI_GETFATTR="${GUFI_TOOL} getfattr"
GUFI_INDEX2DIR="@CMAKE_BINARY_DIR@/src/gufi_index2dir"
GUFI_LS="${GUFI_TOOL} ls"
GUFI_QUERY="@CMAKE_BINARY_DIR@/src/gufi_query"
GUFI_ROLLUP="@CMAKE_BINARY_DIR@/src/gufi_rollup"
GUFI_SQLITE3="@CMAKE_BINARY_DIR@/src/gufi_sqlite3"
GUFI_STAT="${GUFI_TOOL} stat"
GUFI_STATS="${GUFI_TOOL} stats"
GUFI_STAT_BIN="@CMAKE_BINARY_DIR@/src/gufi_stat_bin"
GUFI_TRACE2DIR="@CMAKE_BINARY_DIR@/src/gufi_trace2dir"
GUFI_TRACE2INDEX="@CMAKE_BINARY_DIR@/src/gufi_trace2index"
GUFI_TREESUMMARY="@CMAKE_BINARY_DIR@/src/gufi_treesummary"
GUFI_TREESUMMARY_ALL="@CMAKE_BINARY_DIR@/src/gufi_treesummary_all"
GUFI_UNROLLUP="@CMAKE_BINARY_DIR@/src/gufi_unrollup"
LONGITUDINAL_SNAPSHOT="@CMAKE_BINARY_DIR@/contrib/longitudinal_snapshot.py"
OLDBIGFILES="@CMAKE_BINARY_DIR@/examples/oldbigfiles"
PARALLEL_CPR="@CMAKE_BINARY_DIR@/src/parallel_cpr"
PARALLEL_RMR="@CMAKE_BINARY_DIR@/src/parallel_rmr"
QUERYDBS="@CMAKE_BINARY_DIR@/src/querydbs"
SPLIT_TRACE="@CMAKE_BINARY_DIR@/contrib/split_trace"
TREEDIFF="@CMAKE_BINARY_DIR@/contrib/treediff"
USERFILESPACEHOG="@CMAKE_BINARY_DIR@/examples/userfilespacehog"
USERFILESPACEHOGUSESUMMARY="@CMAKE_BINARY_DIR@/examples/userfilespacehogusesummary"
VERIFYTRACE="@CMAKE_BINARY_DIR@/contrib/verifytrace"
VERIFYTRACEINTREE="@CMAKE_BINARY_DIR@/contrib/verifytraceintree"

AWK="@AWK@"
DIFF="@DIFF@"
GREP="@GREP@"

PWD="$(pwd)"

# shellcheck disable=2050
if [[ "@CMAKE_SYSTEM_NAME@" == "APPLE"  ]] || \
   [[ "@CMAKE_SYSTEM_NAME@" == "Darwin" ]]
then
    STAT_FORMAT="-f"

    XATTR="@XATTR@"

    replace_xattr() {
        sed "
        s/${XATTR//\//\\/} .* \-\- /getfattr /g;
        "
    }
else
    STAT_FORMAT="--printf"

    replace_xattr() {
        sed "
        /getfattr: Removing leading '\/' from absolute path names/d;
        s/getfattr .* \-\- /getfattr /g;
        "
    }
fi

# common strings that need replacing
replace() {
    sed "
    s/${SQLITE3//\//\\/}/sqlite3/g;
    s/${DELUIDGIDSUMMARYRECS//\//\\/}/deluidgidsummaryrecs/g;
    s/${GENERATEGIDSUMMARY//\//\\/}/generategidsummary/g;
    s/${GENERATETREE//\//\\/}/generatetree/g;
    s/${GENERATEUIDSUMMARY//\//\\/}/generateuidsummary/g;
    s/${GENGIDSUMMARYAVOIDENTRIESSCAN//\//\\/}/gengidsummaryavoidentriesscan/g;
    s/${GENUIDSUMMARYAVOIDENTRIESSCAN//\//\\/}/genuidsummaryavoidentriesscan/g;
    s/${GROUPFILESPACEHOG//\//\\/}/groupfilespacehog/g;
    s/${GROUPFILESPACEHOGUSESUMMARY//\//\\/}/groupfilespacehogusesummary/g;
    s/${GUFI_DIR2INDEX//\//\\/}/gufi_dir2index/g;
    s/${GUFI_DIR2TRACE//\//\\/}/gufi_dir2trace/g;
    s/${GUFI_FIND//\//\\/}/gufi_find/g;
    s/${GUFI_GETFATTR//\//\\/}/gufi_getfattr/g;
    s/${GUFI_INDEX2DIR//\//\\/}/gufi_index2dir/g;
    s/${GUFI_LS//\//\\/}/gufi_ls/g;
    s/${GUFI_QUERY//\//\\/}/gufi_query/g;
    s/${GUFI_ROLLUP//\//\\/}/gufi_rollup/g;
    s/${GUFI_SQLITE3//\//\\/}/gufi_sqlite3/g
    s/${GUFI_STAT//\//\\/}/gufi_stat/g
    s/${GUFI_STATS//\//\\/}/gufi_stats/g;
    s/${GUFI_STAT_BIN//\//\\/}/gufi_stat_bin/g
    s/${GUFI_TRACE2DIR//\//\\/}/gufi_trace2dir/g;
    s/${GUFI_TRACE2INDEX//\//\\/}/gufi_trace2index/g;
    s/${GUFI_TREESUMMARY//\//\\/}/gufi_treesummary/g;
    s/${GUFI_TREESUMMARY_ALL//\//\\/}/gufi_treesummary_all/g;
    s/${GUFI_UNROLLUP//\//\\/}/gufi_unrollup/g;
    s/${LONGITUDINAL_SNAPSHOT//\//\\/}/longitudinal_snapshot.py/g;
    s/${OLDBIGFILES//\//\\/}/oldbigfiles/g;
    s/${PARALLEL_CPR//\//\\/}/parallel_cpr/g;
    s/${PARALLEL_RMR//\//\\/}/parallel_rmr/g;
    s/${QUERYDBS//\//\\/}/querydbs/g;
    s/${SPLIT_TRACE//\//\\/}/split_trace/g;
    s/${TREEDIFF//\//\\/}/treediff/g;
    s/${USERFILESPACEHOG//\//\\/}/userfilespacehog/g;
    s/${USERFILESPACEHOGUSESUMMARY//\//\\/}/userfilespacehogusesummary/g;
    s/${VERIFYTRACE//\//\\/}/verifytrace/g;
    s/${VERIFYTRACEINTREE//\//\\/}/verifytraceintree/g;

    s/&vfs=.*//g;
    /gufi_tool/d;
    /-e                          compress work items/d;
    /Started [0-9]* threads. Successfully completed [0-9]* threads./d;

    s/${TEST_DIR//\//\\/}\\///g;
    s/${INDEXROOT//\//\\/}/${BASENAME//\//\\/}/g;
    s/${CONFIG//\//\\/}/\\/etc\\/GUFI\\/config/g;
    s/${PWD//\//\\/}\\///g;

    s/${AWK//\//\\/}/awk/g;
    s/${DIFF//\//\\/}/diff/g;
    s/${GREP//\//\\/}/grep/g;

    s/[[:space:]]*$//g;
    " | replace_xattr
}

# argparse help output changes slightly between versions
replace_argparse() {
    sed ${SED_COMPAT} 's/optional arguments/options/g; s/\[paths \[paths ...\]\]/\[paths ...\]/g;'
}

run_sort() {
    echo "$" "$@"                                  | replace
    # shellcheck disable=SC2294
    eval "${GUFI_PYTHON_TEST_COVERAGE}" "$@"  2>&1 | replace | sort
    echo
}

run_no_sort() {
    echo "$" "$@"                                  | replace
    # shellcheck disable=SC2294
    eval "${GUFI_PYTHON_TEST_COVERAGE}" "$@"  2>&1 | replace
    echo
}

# somewhat force ordering of trace file
order_tracefile() {
    @GREP@ -a "^${BASENAME}${DELIM}"              "$1"
    @GREP@ -a "^${BASENAME}/.hidden${DELIM}"      "$1"
    @GREP@ -a "^${BASENAME}/1KB${DELIM}"          "$1"
    @GREP@ -a "^${BASENAME}/1MB${DELIM}"          "$1"
    @GREP@ -a "^${BASENAME}/file_symlink${DELIM}" "$1"
    @GREP@ -a "^${BASENAME}/old_file${DELIM}"     "$1"
    @GREP@ -a "^${BASENAME}/repeat_name${DELIM}"  "$1"
    @GREP@ -a "^${BASENAME}/directory.*${DELIM}"  "$1"
    @GREP@ -a "^${BASENAME}/leaf.*${DELIM}"       "$1"
    @GREP@ -a "^${BASENAME}/unusual.*${DELIM}"    "$1"
}

remove_indexing_time() {
    @GREP@ -v "Scouts took total of\|Time Spent Indexing:\|Dirs/Sec:\|Files/Sec"
}

pull_ug_summary_columns() {
    UG="$1"
    RELATION="$2"
    WHERE="$3"

    if [[ "${UG}" = "uid" ]]
    then
        SRC="${USER_ID}"
        DST="${TEST_USER_ID}"
    elif [[ "${UG}" = "gid" ]]
    then
        SRC="${GROUP_ID}"
        DST="${TEST_GROUP_ID}"
    fi

    run_sort "${GUFI_QUERY} -d \" \" -S \"SELECT path(), level(), totfiles, totlinks, '[', ${UG}, minuid, maxuid, mingid, maxgid, ']', minsize, maxsize, totltk, totmtk, totltm, totmtm, totmtg, totmtt, totsize, minmtime, maxmtime, minatime, maxatime, totxattr, mincrtime, maxcrtime, minossint1, maxossint1, totossint1, minossint2, maxossint2, totossint2, minossint3, maxossint3, totossint3, minossint4, maxossint4, totossint4, rectype FROM ${RELATION}${WHERE};\" \"${INDEXROOT}\"" | sed ${SED_COMPAT} "s/\[ ${SRC} ${USER_ID} ${USER_ID} ${GROUP_ID} ${GROUP_ID} \]/${DST} ${TEST_USER_ID} ${TEST_USER_ID} ${TEST_GROUP_ID} ${TEST_GROUP_ID}/g;"
}

# set some columns to make test easier
clean_index() {
    INDEX="$1"
    ACTUAL="$2"

    # update xattrs to point to updated inodes
    # do this before updating summary/entries to be able to use actual inodes
    "${GUFI_QUERY}" \
        -a \
        -x \
        -w \
        -I "CREATE TABLE temp_xattrs (inode TEXT, name TEXT, value TEXT);" \
        -S "INSERT INTO temp_xattrs (inode, name, value) SELECT CAST(mtime AS TEXT), xattr_name, xattr_value FROM xsummary WHERE xattr_name IS NOT NULL UNION ALL SELECT CAST(mtime AS TEXT), xattr_name, xattr_value FROM xpentries WHERE xattr_name IS NOT NULL;" \
        -E "DELETE FROM xattrs_pwd; INSERT INTO xattrs_pwd SELECT * FROM temp_xattrs; DELETE from temp_xattrs;" \
        "${INDEX}"

    # update sumamry and entries columns
    "${GUFI_QUERY}" \
        -a \
        -w \
        -S "UPDATE summary SET inode = CAST(mtime AS TEXT), size = mtime, atime = mtime, ctime = mtime;" \
        -E "UPDATE entries SET inode = CAST(mtime AS TEXT), size = mtime, atime = mtime, ctime = mtime;" \
        "${INDEX}"

    "${GUFI_QUERY}" \
        -a \
        -w \
        -S "UPDATE summary SET minatime = (SELECT MIN(mtime) FROM entries), maxatime = (SELECT MAX(mtime) FROM entries);" \
        "${INDEX}"

    # set parent pinodes
    "${SQLITE3}" "${INDEX}/db.db"                        "UPDATE summary SET pinode = '18';"
    "${SQLITE3}" "${INDEX}/directory/db.db"              "UPDATE summary SET pinode = '17';"
    "${SQLITE3}" "${INDEX}/directory/subdirectory/db.db" "UPDATE summary SET pinode = '7';"
    "${SQLITE3}" "${INDEX}/empty_directory/db.db"        "UPDATE summary SET pinode = '17';"
    "${SQLITE3}" "${INDEX}/leaf_directory/db.db"         "UPDATE summary SET pinode = '17';"
    "${SQLITE3}" "${INDEX}/unusual#? directory ,/db.db"  "UPDATE summary SET pinode = '17';"

    if [[ "${ACTUAL}" == "1" ]]
    then
        # directory/subdirectory and directory/subdirectory/repeat_name need their actual inodes
        DIR="$(stat ${STAT_FORMAT} '%i' ${SRCDIR}/directory/subdirectory)"
        FILE="$(stat ${STAT_FORMAT} '%i' ${SRCDIR}/directory/subdirectory/repeat_name)"
        "${SQLITE3}" "${INDEX}/directory/subdirectory/db.db" "UPDATE summary SET inode = '${DIR}' WHERE name == 'subdirectory';"
        "${SQLITE3}" "${INDEX}/directory/subdirectory/db.db" "UPDATE entries SET inode = '${FILE}' WHERE name == 'repeat_name';"
        "${SQLITE3}" "${INDEX}/directory/subdirectory/db.db" "UPDATE xattrs_pwd SET inode = '${DIR}' WHERE inode == '6';"
        "${SQLITE3}" "${INDEX}/directory/subdirectory/db.db" "UPDATE xattrs_pwd SET inode = '${FILE}' WHERE inode == '5';"
    fi
}

if [[ "${GENERATE_INDEX}" == "1" ]]
then
    # generate the tree
    "${GENERATETREE}" "${SRCDIR}"

    # generate the index
    "${GUFI_DIR2INDEX}" -x "${SRCDIR}" "${SEARCH}" > /dev/null

    clean_index "${INDEXROOT}" 1
fi
